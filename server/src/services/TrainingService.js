const { spawn } = require('child_process');
const path = require('path');
const fs = require('fs');
const logger = require('../utils/logger');
const ProcessManager = require('../managers/ProcessManager');
const { JobQueue } = require('../managers/JobQueue');
const PythonEnvService = require('./PythonEnvService');
const settings = require('../config/settings');

const JSON_LOG_PREFIX = '__JSON_LOG__';
const MAX_LOG_LENGTH = 1000;
const MAX_OOM_RETRIES = 3;
const OOM_BATCH_DIVISOR = 2;

class TrainingService {
  constructor() {
    this.processes = ProcessManager;
    this.retryState = {};
    this.isShuttingDown = false;
    this.jobQueue = new JobQueue();
    this.csvWatchers = new Map();
    this.jsonBuffer = new Map();

    this.setupProcessCleanup();
    this.setupQueueListeners();
  }

  setupQueueListeners() {
    this.jobQueue.on('jobStarted', (job) => {
      this.processes.addLog(job.config.project || 'unknown', {
        type: 'system',
        msg: `ğŸ”„ é˜Ÿåˆ—ä»»åŠ¡å¼€å§‹æ‰§è¡Œ: ${job.id}`,
        time: Date.now()
      });
    });

    this.jobQueue.on('jobCompleted', (job) => {
      this.processes.addLog(job.config.project || 'unknown', {
        type: 'system',
        msg: `âœ… é˜Ÿåˆ—ä»»åŠ¡å®Œæˆ: ${job.id}`,
        time: Date.now()
      });

      this.processNextJob();
    });

    this.jobQueue.on('jobFailed', (job) => {
      this.processes.addLog(job.config.project || 'unknown', {
        type: 'system',
        msg: `âŒ é˜Ÿåˆ—ä»»åŠ¡å¤±è´¥: ${job.id} - ${job.error}`,
        time: Date.now()
      });

      this.processNextJob();
    });
  }

  processNextJob() {
    const nextJob = this.jobQueue.getNextJob();
    if (nextJob) {
      logger.info(`Starting next job from queue: ${nextJob.id}`);
      this.executeJob(nextJob);
    } else {
      logger.info('No more jobs in queue');
    }
  }

  async executeJob(job) {
    this.jobQueue.startJob(job.id);

    try {
      await this.startTraining(job.config.project, job.config, 0);
    } catch (err) {
      logger.error(`Job execution failed: ${err.message}`);
      this.jobQueue.completeJob(job.id, err.message);
    }
  }

  async addToQueue(config, priority = 0) {
    const job = this.jobQueue.addJob(config, priority);

    const currentRunning = this.processes.getRunning();
    // å½“å‰ç­–ç•¥ä¸ºå…¨å±€å•ä»»åŠ¡ä¸²è¡Œï¼Œé˜²æ­¢ç”¨æˆ·å¤šGPUåŒæ—¶è®­ç»ƒå¯¼è‡´èµ„æºè€—å°½
    if (currentRunning.length === 0) {
      this.processNextJob();
    }

    return {
      success: true,
      jobId: job.id,
      message: 'ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—',
      queuePosition: this.jobQueue.getPendingJobs().findIndex(j => j.id === job.id) + 1
    };
  }

  setupProcessCleanup() {
    if (typeof process !== 'undefined') {
      process.on('exit', (code) => {
        logger.info(`Process exit event: ${code}, cleaning up child processes...`);
        this.killAllProcesses();
      });

      process.on('SIGINT', () => {
        logger.info('Received SIGINT signal, gracefully shutting down...');
        this.gracefulShutdown('SIGINT');
      });

      process.on('SIGTERM', () => {
        logger.info('Received SIGTERM signal, shutting down...');
        this.gracefulShutdown('SIGTERM');
      });

      process.on('uncaughtException', (err) => {
        logger.error('Uncaught exception, cleaning up...', err);
        this.killAllProcesses();
      });

      logger.info('Process cleanup handlers registered');
    }
  }

  killProcess(pid, force = false) {
    if (!pid) return false;

    const isWindows = process.platform === 'win32';

    try {
      if (isWindows) {
        const { execSync } = require('child_process');
        const signal = force ? '/F' : '';
        execSync(`taskkill ${signal} /PID ${pid} /T`, { stdio: 'ignore' });
        logger.debug(`Killed process ${pid} via taskkill (force: ${force})`);
      } else {
        process.kill(pid, force ? 'SIGKILL' : 'SIGTERM');
        logger.debug(`Killed process ${pid} via signal ${force ? 'SIGKILL' : 'SIGTERM'}`);
      }
      return true;
    } catch (e) {
      if (e.code === 'ESRCH') {
        return true;
      }
      logger.debug(`Failed to kill process ${pid}: ${e.message}`);
      return false;
    }
  }

  async isProcessRunning(pid) {
    if (!pid) return false;

    const isWindows = process.platform === 'win32';

    try {
      if (isWindows) {
        const { execSync } = require('child_process');
        execSync(`tasklist /FI "PID eq ${pid}"`, { stdio: 'ignore' });
        return true;
      } else {
        process.kill(pid, 0);
        return true;
      }
    } catch (e) {
      return false;
    }
  }

  killAllProcesses() {
    const runningProcesses = this.processes.getRunning();
    logger.info(`Cleaning up ${runningProcesses.length} running processes`);

    runningProcesses.forEach(proc => {
      if (proc.pid) {
        this.killProcess(proc.pid, true);
        logger.info(`Killed process ${proc.pid} for project ${proc.projectId}`);
      }
    });
  }

  async gracefulShutdown(signal) {
    this.isShuttingDown = true;
    const runningProcesses = this.processes.getRunning();

    logger.info(`Graceful shutdown: ${runningProcesses.length} processes to terminate`);

    for (const proc of runningProcesses) {
      if (proc.pid) {
        try {
          logger.info(`Sending SIGTERM to process ${proc.pid} (project: ${proc.projectId})`);
          this.killProcess(proc.pid, false);

          const exited = await this.waitForProcessExit(proc.pid, 5000);

          if (!exited) {
            logger.warn(`Process ${proc.pid} did not exit gracefully, sending SIGKILL`);
            this.killProcess(proc.pid, true);
          }

          this.processes.addLog(proc.projectId, {
            type: 'system',
            msg: `è¿›ç¨‹è¢« ${signal} ä¿¡å·ç»ˆæ­¢`,
            time: Date.now()
          });

          logger.info(`Terminated process ${proc.pid} for project ${proc.projectId}`);
        } catch (e) {
          logger.debug(`Error terminating process ${proc.pid}: ${e.message}`);
        }
      }
    }

    logger.info('Graceful shutdown completed');
    process.exit(0);
  }

  async waitForProcessExit(pid, timeoutMs) {
    const startTime = Date.now();

    while (Date.now() - startTime < timeoutMs) {
      const running = await this.isProcessRunning(pid);
      if (!running) {
        return true;
      }
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    return false;
  }

  async getPythonCommand() {
    const env = await PythonEnvService.getBestPython();
    if (!env) {
      throw new Error('No valid Python environment found');
    }
    return { cmd: env.path, info: env };
  }

  buildArgs(config) {
    const args = [
      path.join(__dirname, '..', '..', '..', 'scripts', 'train.py'),
      '--data', config.data,
      '--model', config.model,
      '--epochs', String(config.epochs),
      '--batch', String(config.batch),
      '--imgsz', String(config.imgsz),
      '--project', config.project || '',
      '--name', config.name || 'exp_auto',
      '--device', config.device || '0',
      '--workers', String(config.workers || 0)
    ];

    if (config.resume === true) {
      args.push('--resume');
    }

    if (config.cache_images) args.push('--cache_images');
    args.push('--patience', String(config.patience || 60));
    if (config.cos_lr) args.push('--cos_lr');
    args.push('--optimizer', config.optimizer || 'auto');
    if (config.rect) args.push('--rect');

    if (config.augmentationEnabled !== false) {
      args.push('--degrees', String(config.degrees || 0));
      args.push('--translate', String(config.translate || 0.1));
      args.push('--scale', String(config.scale || 0.5));
      args.push('--shear', String(config.shear || 0));
      args.push('--perspective', String(config.perspective || 0));
      args.push('--fliplr', String(config.fliplr || 0.5));
      args.push('--flipud', String(config.flipud || 0));
      args.push('--hsv_h', String(config.hsv_h || 0.015));
      args.push('--hsv_s', String(config.hsv_s || 0.7));
      args.push('--hsv_v', String(config.hsv_v || 0.4));
      args.push('--mosaic', String(config.mosaic || 1.0));
      args.push('--close_mosaic', String(config.close_mosaic || 0));
      args.push('--mixup', String(config.mixup || 0));
      args.push('--copy_paste', String(config.copy_paste || 0));
      args.push('--erasing', String(config.erasing || 0.4));
      args.push('--crop_fraction', String(config.crop_fraction || 1.0));
    } else {
      args.push('--degrees', '0', '--translate', '0', '--scale', '0');
      args.push('--mosaic', '0');
    }

    args.push('--loss_pose', String(config.loss_pose || 25.0));
    args.push('--loss_box', String(config.loss_box || 7.5));
    args.push('--loss_cls', String(config.loss_cls || 0.5));

    if (config.export_formats) {
      args.push('--export_formats', config.export_formats);
    }

    return args;
  }

  isOOMError(line) {
    const lower = line.toLowerCase();
    return lower.includes('out of memory') ||
      lower.includes('cuda out of memory') ||
      lower.includes('oom') ||
      lower.includes('cudamalloc');
  }

  shouldSkipLog(line) {
    if (!line || line.length === 0) return true;

    const skipPatterns = [
      /^\s*$/,
      /^\s*Class\s+Images\s+Instances\s+Box/,
      /^\s*Epoch\s+GPU_mem\s+box_loss/,
      /^[\d.]+it\/s/,
      /^\d+%\s*[â”â”€â•¸]+/,
    ];

    for (const pattern of skipPatterns) {
      if (pattern.test(line)) return true;
    }

    if (line.includes('â”â”â”â”') || line.includes('â”€â”€â”€â”€') || line.includes('â•¸')) {
      return true;
    }

    return false;
  }

  async start(projectId, config) {
    const existing = this.processes.get(projectId);
    if (existing && existing.status === 'running') {
      return this.addToQueue({ ...config, project: projectId }, config.priority || 0);
    }

    return this.startTraining(projectId, config, 0);
  }

  async startTraining(projectId, config, retryCount = 0) {
    const existing = this.processes.get(projectId);
    if (existing && existing.status === 'running') {
      throw new Error('Training is already in progress for this project');
    }

    this.jsonBuffer.set(projectId, '');

    const { cmd: pythonCmd } = await this.getPythonCommand();
    const args = this.buildArgs(config);

    logger.info(`Starting training for project ${projectId} (attempt ${retryCount + 1}): ${pythonCmd} ${args.join(' ')}`);

    if (retryCount > 0) {
      this.processes.addLog(projectId, {
        type: 'system',
        msg: `ğŸ”„ é‡è¯•è®­ç»ƒ (å°è¯• ${retryCount + 1}/${MAX_OOM_RETRIES + 1})ï¼ŒBatch Size: ${config.batch}`,
        time: Date.now()
      });
    }

    const processState = this.processes.create(projectId);
    this.processes.setStatus(projectId, 'starting');

    const projectPath = config.project || '';
    const csvWatcher = this.watchResultsCSV(projectId, projectPath);
    if (csvWatcher) {
      this.csvWatchers.set(projectId, csvWatcher);
    }

    const child = spawn(pythonCmd, args, {
      windowsHide: true,
      env: { ...process.env, KMP_DUPLICATE_LIB_OK: 'TRUE' }
    });

    this.processes.setPid(projectId, child.pid);
    this.processes.setStatus(projectId, 'running');

    this.retryState[projectId] = {
      retryCount,
      originalBatch: config.batch,
      batchHistory: [config.batch],
      isRetrying: false
    };

    this.processes.addLog(projectId, {
      type: 'system',
      msg: `è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: ${child.pid}ï¼ŒBatch Size: ${config.batch}`,
      time: Date.now()
    });

    child.stdout.on('data', (data) => {
      const chunk = data.toString();
      let buffer = this.jsonBuffer.get(projectId) || '';
      buffer += chunk;

      const lines = buffer.split('\n');
      buffer = lines.pop();

      lines.forEach(line => {
        if (!line.trim()) return;

        if (line.startsWith(JSON_LOG_PREFIX)) {
          try {
            const jsonStr = line.slice(JSON_LOG_PREFIX.length);
            const jsonData = JSON.parse(jsonStr);
            this.processes.addMetric(projectId, {
              ...jsonData,
              time: Date.now()
            });

            if (jsonData.event === 'epoch_end') {
              const parts = [];
              parts.push(`Epoch ${jsonData.epoch}/${jsonData.epochs}`);
              if (jsonData.box_loss !== undefined) parts.push(`box_loss=${jsonData.box_loss.toFixed(4)}`);
              if (jsonData.pose_loss !== undefined) parts.push(`pose_loss=${jsonData.pose_loss.toFixed(4)}`);
              if (jsonData.mAP50 !== undefined) parts.push(`mAP50=${(jsonData.mAP50 * 100).toFixed(1)}%`);
              if (jsonData.pose_mAP50 !== undefined) parts.push(`pose_mAP50=${(jsonData.pose_mAP50 * 100).toFixed(1)}%`);

              this.processes.addLog(projectId, {
                type: 'metric',
                msg: parts.join(' | '),
                time: Date.now()
              });
            }

            if (jsonData.event === 'validation_complete') {
              const m = jsonData.metrics || {};
              this.processes.addLog(projectId, {
                type: 'metric',
                msg: `âœ… éªŒè¯å®Œæˆ - Box mAP@50: ${(m.mAP50 * 100 || 0).toFixed(1)}%, Pose mAP@50: ${(m.pose_mAP50 * 100 || 0).toFixed(1)}%`,
                time: Date.now()
              });
            }
          } catch (e) {
            logger.debug(`Failed to parse JSON log: ${e.message}, raw: ${line.slice(0, 100)}`);
          }
        } else {
          const trimmed = line.trim();

          if (this.shouldSkipLog(trimmed)) {
            return;
          }

          const progressMatch = trimmed.match(/(\d+)\/(\d+)\s+([\d.]+G)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)/);
          if (progressMatch) {
            const [full, epoch, totalEpochs, gpuMem, boxLoss, poseLoss, kobjLoss, clsLoss, dflLoss] = progressMatch;
            this.processes.addMetric(projectId, {
              epoch: parseInt(epoch),
              totalEpochs: parseInt(totalEpochs),
              gpu_mem: gpuMem,
              box_loss: parseFloat(boxLoss),
              pose_loss: parseFloat(poseLoss),
              kobj_loss: parseFloat(kobjLoss),
              cls_loss: parseFloat(clsLoss),
              dfl_loss: parseFloat(dflLoss),
              time: Date.now()
            });
            return;
          }

          const mapMatch = trimmed.match(/all\s+(\d+)\s+(\d+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)/);
          if (mapMatch) {
            const [full, images, instances, boxP, boxR, boxMAP50, boxMAP5095, poseP, poseR, poseMAP50, poseMAP5095] = mapMatch;
            this.processes.addMetric(projectId, {
              box_precision: parseFloat(boxP),
              box_recall: parseFloat(boxR),
              mAP50: parseFloat(boxMAP50),
              mAP50_95: parseFloat(boxMAP5095),
              pose_precision: parseFloat(poseP),
              pose_recall: parseFloat(poseR),
              pose_mAP50: parseFloat(poseMAP50),
              pose_mAP50_95: parseFloat(poseMAP5095),
              time: Date.now()
            });

            this.processes.addLog(projectId, {
              type: 'metric',
              msg: `ğŸ“Š éªŒè¯æŒ‡æ ‡ - Box: P=${boxP} R=${boxR} mAP@50=${(parseFloat(boxMAP50) * 100).toFixed(1)}% | Pose: P=${poseP} R=${poseR} mAP@50=${(parseFloat(poseMAP50) * 100).toFixed(1)}%`,
              time: Date.now()
            });
            return;
          }

          if (trimmed.includes('Class') && trimmed.includes('Images') && trimmed.includes('Box(P')) {
            return;
          }

          if (trimmed.startsWith('Epoch') && trimmed.includes('GPU_mem')) {
            return;
          }

          if (trimmed.includes('â”â”â”â”') || trimmed.includes('â”€â”€â”€â”€') || trimmed.includes('â•¸')) {
            return;
          }

          this.processes.addLog(projectId, {
            type: 'stdout',
            msg: trimmed,
            time: Date.now()
          });
        }
      });
    });

    child.stderr.on('data', (data) => {
      const lines = data.toString().split('\n');
      lines.forEach(line => {
        if (line.trim()) {
          const trimmed = line.trim();
          logger.error(`[Train ${projectId}] ${trimmed}`);

          let errorType = null;
          let errorSuggestions = [];
          const lowerLine = trimmed.toLowerCase();

          if (this.isOOMError(trimmed)) {
            errorType = 'æ˜¾å­˜ä¸è¶³ (OOM)';
            errorSuggestions = [
              'å‡å° batch_size å‚æ•°',
              'å‡å° imgsz å›¾ç‰‡å°ºå¯¸',
              'å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹'
            ];

            this.processes.addLog(projectId, {
              type: 'error',
              msg: `âš ï¸ æ£€æµ‹åˆ°æ˜¾å­˜ä¸è¶³ (OOM) é”™è¯¯ï¼`,
              time: Date.now()
            });

            this.handleOOMError(projectId, config, retryCount);
          }
          else if (lowerLine.includes('no cuda gpu') || lowerLine.includes('no gpu') || lowerLine.includes('cuda is not available')) {
            errorType = 'GPU ä¸å¯ç”¨';
            errorSuggestions = [
              'è¯·ç¡®è®¤å·²æ­£ç¡®å®‰è£… NVIDIA æ˜¾å¡é©±åŠ¨',
              'å°† device å‚æ•°æ”¹ä¸º cpu ä½¿ç”¨ CPU æ¨¡å¼'
            ];
          }
          else if (lowerLine.includes('cuda') && (lowerLine.includes('error') || lowerLine.includes('failed'))) {
            errorType = 'CUDA ç›¸å…³é”™è¯¯';
            errorSuggestions = [
              'å¯èƒ½æ˜¯ CUDA ç‰ˆæœ¬ä¸æ˜¾å¡é©±åŠ¨ä¸åŒ¹é…',
              'å°è¯•æ›´æ–° NVIDIA é©±åŠ¨åˆ°æœ€æ–°ç‰ˆæœ¬'
            ];
          }

          let displayMsg = trimmed;
          if (errorType) {
            displayMsg = `[${errorType}] ${trimmed}`;
            if (errorSuggestions.length > 0) {
              this.processes.addLog(projectId, {
                type: 'suggestion',
                msg: `ğŸ’¡ å»ºè®®: ${errorSuggestions.join('; ')}`,
                time: Date.now()
              });
            }
          }

          this.processes.addLog(projectId, {
            type: 'stderr',
            msg: displayMsg,
            time: Date.now()
          });
        }
      });
    });

    child.on('close', (code) => {
      const retryState = this.retryState[projectId];

      const watcher = this.csvWatchers.get(projectId);
      if (watcher) {
        watcher.close();
        this.csvWatchers.delete(projectId);
        logger.debug(`Closed CSV watcher for project ${projectId}`);
      }

      this.jsonBuffer.delete(projectId);

      if (code === 0) {
        const status = 'completed';
        this.processes.setStatus(projectId, status);
        this.processes.addLog(projectId, {
          type: 'system',
          msg: `âœ… è®­ç»ƒå®Œæˆï¼è¿›ç¨‹é€€å‡ºç : ${code}`,
          time: Date.now()
        });
        logger.info(`Training for project ${projectId} ${status}`);
      }
      else if (retryState && retryState.isRetrying && retryState.retryCount <= MAX_OOM_RETRIES) {
        logger.info(`Waiting for OOM retry for project ${projectId}`);
      }
      else {
        const status = 'failed';
        this.processes.setStatus(projectId, status);
        this.processes.addLog(projectId, {
          type: 'system',
          msg: `âŒ è®­ç»ƒå¤±è´¥ï¼è¿›ç¨‹é€€å‡ºç : ${code}`,
          time: Date.now()
        });
        logger.info(`Training for project ${projectId} ${status}`);
      }

      delete this.retryState[projectId];
    });

    child.on('error', (err) => {
      logger.error(`Training process error for ${projectId}:`, err);
      this.processes.setStatus(projectId, 'failed');
      this.processes.addLog(projectId, {
        type: 'system',
        msg: `å¯åŠ¨å¤±è´¥: ${err.message}`,
        time: Date.now()
      });
    });

    return { success: true, pid: child.pid, name: config.name || 'exp_auto', batch: config.batch };
  }

  async handleOOMError(projectId, config, retryCount) {
    const retryState = this.retryState[projectId];

    if (!retryState) {
      logger.error(`No retry state found for project ${projectId}`);
      return;
    }

    if (retryCount >= MAX_OOM_RETRIES) {
      this.processes.addLog(projectId, {
        type: 'system',
        msg: `âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (${MAX_OOM_RETRIES})ï¼Œè®­ç»ƒç»ˆæ­¢`,
        time: Date.now()
      });

      this.processes.addLog(projectId, {
        type: 'suggestion',
        msg: `ğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:\n1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (yolov8n æˆ– yolov8s)\n2. å‡å° imgsz å›¾ç‰‡å°ºå¯¸\n3. ä½¿ç”¨ CPU æ¨¡å¼è®­ç»ƒ (device: cpu)\n4. æ£€æŸ¥æ˜¾å¡é©±åŠ¨æ˜¯å¦éœ€è¦æ›´æ–°`,
        time: Date.now()
      });

      retryState.isRetrying = false;
      return;
    }

    retryState.isRetrying = true;
    retryState.retryCount = retryCount + 1;

    const newBatch = Math.max(1, Math.floor(config.batch / OOM_BATCH_DIVISOR));

    if (config.batch === 1 || newBatch === config.batch) {
      this.processes.addLog(projectId, {
        type: 'error',
        msg: `âŒ Batch Size å·²é™è‡³ 1 ä»ç„¶æ˜¾å­˜ä¸è¶³ï¼Œæ— æ³•ç»§ç»­è‡ªåŠ¨ä¿®å¤ã€‚è¯·å°è¯•å‡å° imgsz æˆ–æ›´æ¢æ›´å°çš„æ¨¡å‹ã€‚`,
        time: Date.now()
      });

      this.processes.addLog(projectId, {
        type: 'suggestion',
        msg: `ğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:\n1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (yolov8n æˆ– yolov8s)\n2. å‡å° imgsz å›¾ç‰‡å°ºå¯¸\n3. ä½¿ç”¨ CPU æ¨¡å¼è®­ç»ƒ (device: cpu)\n4. æ£€æŸ¥æ˜¾å¡é©±åŠ¨æ˜¯å¦éœ€è¦æ›´æ–°`,
        time: Date.now()
      });

      retryState.isRetrying = false;
      this.processes.setStatus(projectId, 'failed');
      return;
    }

    retryState.batchHistory.push(newBatch);

    this.processes.addLog(projectId, {
      type: 'system',
      msg: `ğŸ”„ æ˜¾å­˜ä¸è¶³ï¼å°†åœ¨ 3 ç§’åè‡ªåŠ¨é‡è¯•ï¼ŒBatch Size: ${config.batch} â†’ ${newBatch}`,
      time: Date.now()
    });

    logger.info(`OOM detected for project ${projectId}, will retry with batch size ${newBatch}`);

    try {
      if (this.processes.get(projectId) && this.processes.get(projectId).pid) {
        this.killProcess(this.processes.get(projectId).pid, true);
        logger.info(`Killed old process for project ${projectId}`);
      }
    } catch (e) {
      logger.debug(`Error during cleanup: ${e.message}`);
    }

    await new Promise(resolve => setTimeout(resolve, 3000));

    this.processes.setStatus(projectId, 'idle');
    logger.info(`Reset process status to 'idle' for OOM retry of project ${projectId}`);

    const newConfig = {
      ...config,
      batch: newBatch
    };

    try {
      await this.startTraining(projectId, newConfig, retryState.retryCount);
    } catch (err) {
      logger.error(`Retry failed for project ${projectId}:`, err);
      this.processes.setStatus(projectId, 'failed');
      this.processes.addLog(projectId, {
        type: 'system',
        msg: `âŒ é‡è¯•å¤±è´¥: ${err.message}`,
        time: Date.now()
      });
    }
  }

  async stop(projectId) {
    const processState = this.processes.get(projectId);
    if (!processState || processState.status !== 'running' || !processState.pid) {
      throw new Error('No running training process found');
    }

    if (this.retryState[projectId]) {
      this.retryState[projectId].isRetrying = false;
    }

    try {
      this.killProcess(processState.pid, true);
      this.processes.setStatus(projectId, 'stopped');
      this.processes.addLog(projectId, {
        type: 'system',
        msg: 'ç”¨æˆ·æ‰‹åŠ¨åœæ­¢è®­ç»ƒ',
        time: Date.now()
      });
      return { success: true };
    } catch (err) {
      logger.error(`Failed to stop training for ${projectId}:`, err);
      throw new Error(`Failed to stop process: ${err.message}`);
    }
  }

  getStatus(projectId) {
    const processState = this.processes.get(projectId);
    const retryState = this.retryState[projectId];

    if (!processState) {
      return { status: 'idle', logs: [], metrics: [] };
    }

    const response = {
      status: processState.status,
      logs: processState.logs.slice(-100),
      metrics: processState.metrics,
      pid: processState.pid,
      startTime: processState.startTime,
      endTime: processState.endTime
    };

    if (retryState) {
      response.retryInfo = {
        retryCount: retryState.retryCount,
        originalBatch: retryState.originalBatch,
        batchHistory: retryState.batchHistory,
        isRetrying: retryState.isRetrying
      };
    }

    return response;
  }

  getQueueStatus() {
    return {
      stats: this.jobQueue.getStats(),
      jobs: this.jobQueue.getAllJobs().map(job => ({
        id: job.id,
        config: job.config,
        priority: job.priority,
        status: job.status,
        createdAt: job.createdAt,
        startedAt: job.startedAt,
        completedAt: job.completedAt,
        error: job.error,
        retryCount: job.retryCount
      }))
    };
  }

  async cancelJob(jobId) {
    return this.jobQueue.cancelJob(jobId);
  }

  async removeJob(jobId) {
    return this.jobQueue.removeJob(jobId);
  }

  async reorderQueue(fromIndex, toIndex) {
    return this.jobQueue.reorderJobs(fromIndex, toIndex);
  }

  async clearQueue() {
    return this.jobQueue.clearCompleted();
  }

  watchResultsCSV(projectId, projectPath) {
    const csvPath = path.join(projectPath, 'results.csv');
    let lastSize = 0;
    let epochTimestamps = [];
    const WINDOW_SIZE = 5;

    if (!fs.existsSync(csvPath)) {
      logger.debug(`results.csv not found at ${csvPath}`);
      return null;
    }

    try {
      lastSize = fs.statSync(csvPath).size;
    } catch (e) {
      logger.debug(`Failed to get initial file size: ${e.message}`);
    }

    const watcher = fs.watch(csvPath, (eventType) => {
      if (eventType !== 'change') return;

      setTimeout(() => {
        try {
          const stats = fs.statSync(csvPath);
          const newSize = stats.size;

          if (newSize > lastSize) {
            const stream = fs.createReadStream(csvPath, {
              start: lastSize,
              end: newSize - 1,
              encoding: 'utf-8'
            });

            let newData = '';
            stream.on('data', (chunk) => {
              newData += chunk;
            });

            stream.on('end', () => {
              if (newData.trim()) {
                const lines = newData.trim().split('\n');

                for (const line of lines) {
                  if (line.includes('epoch')) continue;

                  const parts = line.split(',');
                  if (parts.length < 3) continue;

                  const epochMatch = parts[0].trim();
                  const epoch = parseInt(epochMatch);

                  if (isNaN(epoch)) continue;

                  const now = Date.now();
                  if (epochTimestamps.length > 0) {
                    const lastEpochTime = epochTimestamps[epochTimestamps.length - 1];
                    const epochDuration = now - lastEpochTime;

                    epochTimestamps.push(now);

                    if (epochTimestamps.length > WINDOW_SIZE + 10) {
                      epochTimestamps = epochTimestamps.slice(-WINDOW_SIZE);
                    }

                    const recentDurations = epochTimestamps.slice(-WINDOW_SIZE);
                    const avgDuration = recentDurations.reduce((a, b) => a + b, 0) / recentDurations.length;
                    const remainingEpochs = 150 - epoch;
                    const etaSeconds = Math.round(remainingEpochs * avgDuration / 1000);

                    this.processes.addMetric(projectId, {
                      epoch,
                      eta_seconds: etaSeconds,
                      avg_epoch_time: Math.round(avgDuration),
                      time: now
                    });
                  } else {
                    epochTimestamps.push(now);
                  }

                  const metrics = {
                    epoch,
                    time: now
                  };

                  const metricNames = [
                    'train/box_loss', 'train/cls_loss', 'train/dfl_loss',
                    'metrics/precision', 'metrics/recall', 'metrics/map50', 'metrics/map50-95',
                    'val/box_loss', 'val/cls_loss', 'val/dfl_loss'
                  ];

                  metricNames.forEach((name, idx) => {
                    const colIdx = idx + 1;
                    if (parts[colIdx]) {
                      const val = parseFloat(parts[colIdx].trim());
                      if (!isNaN(val)) {
                        metrics[name] = val;
                      }
                    }
                  });

                  this.processes.addMetric(projectId, metrics);
                }
              }
              lastSize = newSize;
            });
          }
        } catch (e) {
          logger.debug(`Error reading CSV: ${e.message}`);
        }
      }, 100);
    });

    watcher.on('error', (err) => {
      logger.error(`CSV watcher error: ${err.message}`);
    });

    return watcher;
  }

  async startDryRun(projectId, config) {
    const runningProcesses = this.processes.getRunning();
    if (runningProcesses.length > 0) {
      return {
        success: false,
        error: 'å½“å‰å·²æœ‰æ­£åœ¨è¿›è¡Œçš„è®­ç»ƒä»»åŠ¡ï¼Œæ— æ³•å¯åŠ¨æµ‹è¯•è¿è¡Œã€‚è¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆæˆ–ç»ˆæ­¢åå†è¯•ã€‚'
      };
    }

    const dryRunConfig = {
      ...config,
      epochs: 1,
      batch: Math.min(config.batch || 16, 2),
      name: (config.name || 'exp') + '_dryrun',
      project: config.project || 'dryrun_test'
    };

    logger.info(`Starting dry run for project ${projectId}`);

    this.processes.addLog(projectId, {
      type: 'system',
      msg: 'ğŸ”¬ å¼€å§‹æµ‹è¯•è¿è¡Œ (Dry Run)...',
      time: Date.now()
    });

    this.processes.addLog(projectId, {
      type: 'system',
      msg: `   - Epochs: 1 (æ­£å¼è®­ç»ƒ: ${config.epochs})`,
      time: Date.now()
    });

    this.processes.addLog(projectId, {
      type: 'system',
      msg: `   - Batch Size: ${dryRunConfig.batch} (æ­£å¼è®­ç»ƒ: ${config.batch})`,
      time: Date.now()
    });

    try {
      await this.startTraining(projectId, dryRunConfig, 0);
      return { success: true, message: 'Dry run started' };
    } catch (err) {
      return { success: false, error: err.message };
    }
  }
}

module.exports = new TrainingService();
